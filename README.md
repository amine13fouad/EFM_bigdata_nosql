Reddit Scraper avec Playwright & MongoDB
ğŸ“Œ Description

Ce projet est un scraper Reddit automatisÃ© Ã©crit en Python.
Il permet de :

Rechercher des posts Reddit via une URL de recherche donnÃ©e

Ouvrir chaque post trouvÃ©

Extraire :

le titre

le contenu du post

lâ€™ensemble des commentaires, y compris les rÃ©ponses imbriquÃ©es

Stocker les donnÃ©es dans une base MongoDB (MongoDB Atlas)

âš ï¸ Ce script nâ€™utilise pas lâ€™API officielle de Reddit. Il repose sur un navigateur automatisÃ© (Playwright) avec cookies pour Ã©viter les blocages.

Le fonctionnement et la structure dÃ©crits ci-dessous sont directement basÃ©s sur le fichier source 

test

.

ğŸ› ï¸ Technologies utilisÃ©es

Python 3

Playwright (Chromium) â€“ automatisation du navigateur

MongoDB / MongoDB Atlas

pymongo â€“ connexion et insertion de donnÃ©es

JSON â€“ gestion des cookies

Reddit Web (DOM scraping)

ğŸ“‚ Structure du script

Le script est organisÃ© en plusieurs sections claires :

â”œâ”€â”€ Configuration
â”œâ”€â”€ Connexion MongoDB
â”œâ”€â”€ Gestion des cookies
â”œâ”€â”€ Fonctions utilitaires (scroll, extraction)
â”œâ”€â”€ Scraping des posts
â””â”€â”€ Boucle principale

âš™ï¸ Configuration

Les paramÃ¨tres principaux sont dÃ©finis en haut du fichier :

SEARCH_URL = "https://www.reddit.com/search/?q=caf+morocco&type=posts&sort=new"
COOKIE_PATH = "cookies.json"

MONGO_URI = "mongodb+srv://..."
DB_NAME = "EFMBIGDATA"
COLLECTION_NAME = "reddit_posts"

Explication :

SEARCH_URL : URL de recherche Reddit (modifiable selon le mot-clÃ©)

COOKIE_PATH : fichier contenant les cookies Reddit exportÃ©s

MONGO_URI : URI de connexion MongoDB Atlas

DB_NAME / COLLECTION_NAME : base et collection cibles

ğŸª Gestion des cookies Reddit

Reddit bloque rapidement les scrapers non authentifiÃ©s.
Ce script charge donc des cookies existants via :

load_cookies(context)

Fonctionnement :

Lecture du fichier cookies.json

Normalisation du format des cookies

Injection dans le contexte Playwright avant toute navigation

âš ï¸ Sans cookies valides :

CAPTCHA

pages vides

blocage complet du scraping

ğŸ”„ Scroll dynamique

Reddit charge les posts et commentaires dynamiquement.

La fonction :

scroll_until_loaded(page)


Scroll automatiquement la page

Attend que la hauteur du DOM cesse dâ€™augmenter

Ã‰vite de scraper des pages partiellement chargÃ©es

ğŸ’¬ Extraction des commentaires (rÃ©cursive)

Le point le plus important du script est lâ€™extraction hiÃ©rarchique des commentaires.

Fonction clÃ© :
extract_comments(comment_element, depth=0)

Ce quâ€™elle fait :

RÃ©cupÃ¨re le texte du commentaire

Stocke le niveau de profondeur (depth)

Appelle rÃ©cursivement les rÃ©ponses imbriquÃ©es

Structure finale dâ€™un commentaire :
{
  "depth": 2,
  "text": "Contenu du commentaire"
}


Cela permet :

une analyse de threads

un traitement NLP ultÃ©rieur

une reconstruction de lâ€™arbre de discussion

ğŸ“ Scraping dâ€™un post Reddit

La fonction :

scrape_post(page)


RÃ©cupÃ¨re :

Titre du post

Contenu textuel

Tous les commentaires

Nombre total de commentaires extraits

Retourne un dictionnaire structurÃ© prÃªt Ã  Ãªtre insÃ©rÃ© en base.

ğŸ—„ï¸ Stockage MongoDB

Chaque post est insÃ©rÃ© sous forme de document :

{
  "search_url": "...",
  "post_url": "...",
  "scraped_at": "UTC datetime",
  "title": "...",
  "content": "...",
  "comments": [...],
  "comment_count": 42
}


ğŸ“Œ Lâ€™insertion se fait post par post, sans mise Ã  jour ni dÃ©duplication.

â–¶ï¸ Boucle principale

Le script :

Ouvre Reddit via Playwright

Charge les cookies

Charge la page de recherche

Parcourt chaque post trouvÃ©

Scrape le contenu

InsÃ¨re dans MongoDB

Retourne Ã  la page de recherche

Continue jusquâ€™Ã  Ã©puisement des posts
